#!/usr/bin/env python3
"""
Discord Chat to Supabase Collector
ìµœê·¼ 5ì¼ì¹˜ Discord ë©”ì‹œì§€ë¥¼ ìˆ˜ì§‘í•´ì„œ Supabaseì— ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import json
import subprocess
import os
import tempfile
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any
import logging
from supabase import create_client, Client
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DiscordToSupabaseCollector:
    def __init__(self, supabase_url: str, supabase_key: str, discord_token: str):
        """
        Initialize the collector
        
        Args:
            supabase_url: Supabase project URL
            supabase_key: Supabase API key  
            discord_token: Discord user or bot token
        """
        self.supabase: Client = create_client(supabase_url, supabase_key)
        self.discord_token = discord_token
        self.discord_exporter_path = "./bin/DiscordChatExporter.Cli"
        
    def export_messages(self, channel_id: str, days: int = 5) -> str:
        """
        Export messages from Discord channel using DiscordChatExporter
        
        Args:
            channel_id: Discord channel ID
            days: Number of days to go back
            
        Returns:
            Path to the exported JSON file
        """
        start_time = time.time()
        logger.info(f"â° [STEP 1] Discord ë©”ì‹œì§€ ë‚´ë³´ë‚´ê¸° ì‹œì‘: {channel_id} (ìµœê·¼ {days}ì¼)")
        
        # ë‚ ì§œ ê³„ì‚° (5ì¼ ì „)
        after_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
        
        # ì„ì‹œ ì¶œë ¥ íŒŒì¼
        output_file = f"messages_{channel_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        # DiscordChatExporter CLI ëª…ë ¹ì–´
        cmd = [
            self.discord_exporter_path,
            "export",
            "--channel", channel_id,
            "--token", self.discord_token,
            "--format", "Json",
            "--after", after_date,
            "--output", output_file,
            "--media", "false"  # ë¯¸ë””ì–´ ë‹¤ìš´ë¡œë“œ ì•ˆí•¨ (ì†ë„ í–¥ìƒ)
        ]
        
        logger.info(f"ëª…ë ¹ì–´: {' '.join(cmd)}")
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True)
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.info(f"âœ… [STEP 1] ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {output_file} (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            return output_file
        except subprocess.CalledProcessError as e:
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.error(f"âŒ [STEP 1] DiscordChatExporter ì‹¤í–‰ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ): {e}")
            logger.error(f"STDOUT: {e.stdout}")
            logger.error(f"STDERR: {e.stderr}")
            raise
    
    def parse_discord_json(self, json_file: str) -> List[Dict[str, Any]]:
        """
        Parse Discord JSON export file
        
        Args:
            json_file: Path to JSON file
            
        Returns:
            List of parsed message dictionaries
        """
        start_time = time.time()
        logger.info(f"â° [STEP 2] JSON íŒŒì¼ íŒŒì‹± ì‹œì‘: {json_file}")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            messages = []
            channel_info = data.get('channel', {})
            guild_info = data.get('guild', {})
            
            for msg in data.get('messages', []):
                parsed_msg = {
                    'id': int(msg['id']),
                    'channel_id': int(channel_info.get('id', 0)),
                    'channel_name': channel_info.get('name', ''),
                    'server_id': int(guild_info.get('id', 0)) if guild_info.get('id') else None,
                    'server_name': guild_info.get('name', ''),
                    'author_id': int(msg['author']['id']),
                    'author_name': msg['author']['name'],
                    'author_discriminator': msg['author'].get('discriminator', ''),
                    'author_avatar': msg['author'].get('avatarUrl', ''),
                    'content': msg.get('content', ''),
                    'timestamp': msg['timestamp'],
                    'message_type': msg.get('type', 'Default'),
                    'is_pinned': msg.get('isPinned', False),
                    'reference_message_id': int(msg['reference']['messageId']) if msg.get('reference', {}).get('messageId') else None,
                    'attachments': json.dumps(msg.get('attachments', [])),
                    'embeds': json.dumps(msg.get('embeds', [])),
                    'reactions': json.dumps(msg.get('reactions', [])),
                    'mentions': json.dumps(msg.get('mentions', []))
                }
                messages.append(parsed_msg)
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.info(f"âœ… [STEP 2] íŒŒì‹± ì™„ë£Œ: {len(messages)}ê°œ ë©”ì‹œì§€ (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            return messages
            
        except Exception as e:
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.error(f"âŒ [STEP 2] JSON íŒŒì‹± ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ): {e}")
            raise
    
    def save_to_supabase(self, messages: List[Dict[str, Any]]) -> None:
        """
        Save messages to Supabase
        
        Args:
            messages: List of message dictionaries
        """
        if not messages:
            logger.warning("ì €ì¥í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        start_time = time.time()
        logger.info(f"â° [STEP 3] Supabaseì— {len(messages)}ê°œ ë©”ì‹œì§€ ì €ì¥ ì‹œì‘")
        
        try:
            # ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥ (í•œ ë²ˆì— ë„ˆë¬´ ë§ì´ ë³´ë‚´ì§€ ì•Šê¸° ìœ„í•´)
            batch_size = 100
            for i in range(0, len(messages), batch_size):
                batch_start_time = time.time()
                batch = messages[i:i + batch_size]
                
                # UPSERT ì‚¬ìš© (ì¤‘ë³µ ë©”ì‹œì§€ ì²˜ë¦¬)
                result = self.supabase.table('discord_messages').upsert(
                    batch,
                    on_conflict='id'
                ).execute()
                
                batch_end_time = time.time()
                batch_elapsed = batch_end_time - batch_start_time
                logger.info(f"  ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1} ì €ì¥ ì™„ë£Œ: {len(batch)}ê°œ ë©”ì‹œì§€ (ë°°ì¹˜ ì†Œìš”ì‹œê°„: {batch_elapsed:.2f}ì´ˆ)")
            
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.info(f"âœ… [STEP 3] ëª¨ë“  ë©”ì‹œì§€ ì €ì¥ ì™„ë£Œ (ì´ ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            
        except Exception as e:
            end_time = time.time()
            elapsed_time = end_time - start_time
            logger.error(f"âŒ [STEP 3] Supabase ì €ì¥ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {elapsed_time:.2f}ì´ˆ): {e}")
            raise
    
    def collect_and_save(self, channel_id: str, days: int = 5) -> None:
        """
        Complete workflow: export, parse, and save messages
        
        Args:
            channel_id: Discord channel ID
            days: Number of days to go back
        """
        total_start_time = time.time()
        logger.info(f"ğŸš€ ì „ì²´ ì‘ì—… ì‹œì‘: ì±„ë„ {channel_id} (ìµœê·¼ {days}ì¼)")
        
        try:
            # 1. Discordì—ì„œ ë©”ì‹œì§€ ë‚´ë³´ë‚´ê¸°
            json_file = self.export_messages(channel_id, days)
            
            # 2. JSON íŒŒì¼ íŒŒì‹±
            messages = self.parse_discord_json(json_file)
            
            # 3. Supabaseì— ì €ì¥
            self.save_to_supabase(messages)
            
            # 4. ì„ì‹œ íŒŒì¼ ì •ë¦¬
            cleanup_start_time = time.time()
            logger.info(f"â° [STEP 4] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹œì‘")
            if os.path.exists(json_file):
                os.remove(json_file)
                cleanup_end_time = time.time()
                cleanup_elapsed = cleanup_end_time - cleanup_start_time
                logger.info(f"âœ… [STEP 4] ì„ì‹œ íŒŒì¼ ì‚­ì œ: {json_file} (ì†Œìš”ì‹œê°„: {cleanup_elapsed:.2f}ì´ˆ)")
            
            total_end_time = time.time()
            total_elapsed = total_end_time - total_start_time
            logger.info(f"ğŸ‰ ì „ì²´ ì‘ì—… ì™„ë£Œ! (ì´ ì†Œìš”ì‹œê°„: {total_elapsed:.2f}ì´ˆ)")
            
            # ì‹œê°„ ìš”ì•½ ì¶œë ¥
            logger.info("=" * 50)
            logger.info("ğŸ“Š ì‘ì—… ì‹œê°„ ìš”ì•½:")
            logger.info(f"  ì „ì²´ ì‘ì—… ì‹œê°„: {total_elapsed:.2f}ì´ˆ ({total_elapsed/60:.1f}ë¶„)")
            logger.info("=" * 50)
            
        except Exception as e:
            total_end_time = time.time()
            total_elapsed = total_end_time - total_start_time
            logger.error(f"âŒ ì‘ì—… ì‹¤íŒ¨ (ê²½ê³¼ì‹œê°„: {total_elapsed:.2f}ì´ˆ): {e}")
            raise


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤
    """
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
    from config import SUPABASE_URL, SUPABASE_KEY, DISCORD_TOKEN, DEFAULT_CHANNEL_ID, COLLECTION_DAYS, validate_config
    
    # ì„¤ì • ê²€ì¦
    try:
        validate_config()
    except ValueError as e:
        logger.error(str(e))
        return
        
    CHANNEL_ID = DEFAULT_CHANNEL_ID
    
    # ìˆ˜ì§‘ê¸° ìƒì„± ë° ì‹¤í–‰
    collector = DiscordToSupabaseCollector(
        supabase_url=SUPABASE_URL,
        supabase_key=SUPABASE_KEY,
        discord_token=DISCORD_TOKEN
    )
    
    # ë©”ì‹œì§€ ìˆ˜ì§‘ ë° ì €ì¥ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì •ëœ ê¸°ê°„)
    collector.collect_and_save(channel_id=CHANNEL_ID, days=COLLECTION_DAYS)


if __name__ == "__main__":
    main() 